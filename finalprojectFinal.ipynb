{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Basic Data Science Projects using Python, NumPy, Pandas, Matplotlib, Regular Expressions, and SQL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "*By: Prof. James Abello, Haoyang Zhang*\n",
    "\n",
    "*Computer Science Department*\n",
    "\n",
    "*Rutgers University*\n",
    "\n",
    "*Nov. 21, 2024.*\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic 7: Leet Speak (regular expressions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Objective:** Translate English text to Leet Speak and vice versa using regular expressions.\n",
    "\n",
    "#### **Estimated Completion Time: 5 hours**\n",
    "\n",
    "Leet (or \"1337\") speak is a language that uses various combinations of characters to replace Latin letters. For example, the word \"leet\" is written as \"1337\" in leet speak.\n",
    "\n",
    "In this project, you will write a Python program to:\n",
    "\n",
    "- Encode a given string into leet speak by replacing certain letters with their corresponding leet speak characters.\n",
    "- Decode a leet speak string back to the original string by reversing the substitutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good reference is:\n",
    "\n",
    "> L33t sp34k ch34t sh33t by Roald Craenen\n",
    "> \n",
    "> https://www.gamehouse.com/blog/leet-speak-cheat-sheet/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Level 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this level, we will focus on a basic one-to-one mapping of characters without ambiguity. The mapping is as follows:\n",
    "\n",
    "| Latin | Leet |\n",
    "|-------|------|\n",
    "| A     | 4    |\n",
    "| B     | 8    |\n",
    "| C     | (    |\n",
    "| D     | )    |\n",
    "| E     | 3    |\n",
    "| F     | ƒ    |\n",
    "| G     | 6    |\n",
    "| H     | #    |\n",
    "| I     | !    |\n",
    "| J     | ]    |\n",
    "| K     | \\|   |\n",
    "| L     | 1    |\n",
    "| M     | м    |\n",
    "| N     | и    |\n",
    "| O     | Ø    |\n",
    "| P     | 9    |\n",
    "| Q     | 2    |\n",
    "| R     | Я    |\n",
    "| S     | 5    |\n",
    "| T     | 7    |\n",
    "| U     | µ    |\n",
    "| V     | √    |\n",
    "| W     | ω    |\n",
    "| X     | Ж    |\n",
    "| Y     | ¥    |\n",
    "| Z     | %    |\n",
    "\n",
    "Note: this version does not map any characters to latin letters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a Python function `encode_all_1()` that takes a string as input and encodes all Latin letters to leet speak using the mapping above.\n",
    "\n",
    "You can assume that the input text contains only uppercase Latin letters, lowercase Latin letters, and spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def encode_all_1(text):\n",
    "    \"\"\"\n",
    "    Encode all Latin letters to leet speak\n",
    "    IN: text, str, input text\n",
    "    OUT: str, leet speak text\n",
    "    \"\"\"\n",
    "\n",
    "    text = re.sub('[Aa]', '4', text)\n",
    "    text = re.sub('[Bb]', '8', text)\n",
    "    text = re.sub('[Cc]', '(', text)\n",
    "    text = re.sub('[Dd]', ')', text)\n",
    "    text = re.sub('[Ee]', '3', text)\n",
    "    text = re.sub('[Ff]', 'f', text)\n",
    "    text = re.sub('[Gg]', '6', text)\n",
    "    text = re.sub('[Hh]', '#', text)\n",
    "    text = re.sub('[Ii]', '!', text)\n",
    "    text = re.sub('[Jj]', 'j', text)\n",
    "    text = re.sub('[Kk]', '|', text)\n",
    "    text = re.sub('[Ll]', '1', text)\n",
    "    text = re.sub('[Mm]', 'M', text)\n",
    "    text = re.sub('[Nn]', 'n', text)\n",
    "    text = re.sub('[Oo]', '0', text)\n",
    "    text = re.sub('[Pp]', '9', text)\n",
    "    text = re.sub('[Qq]', '2', text)\n",
    "    text = re.sub('[Rr]', 'R', text)\n",
    "    text = re.sub('[Ss]', '5', text)\n",
    "    text = re.sub('[Tt]', '7', text)\n",
    "    text = re.sub('[Uu]', 'µ', text)\n",
    "    text = re.sub('[Vv]', '√', text)\n",
    "    text = re.sub('[Ww]', 'ω', text)\n",
    "    text = re.sub('[Xx]', 'X', text)\n",
    "    text = re.sub('[Yy]', '¥', text)\n",
    "    text = re.sub('[Zz]', '%', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4488(())33ff66##!!jj||11MMnn009922RR5577µµ√√ωωXX¥¥%%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(encode_all_1(\"aAbBcCdDeEfFgGhHiIjJkKlLmMnNoOpPqQrRsStTuUvVwWxXyYzZ\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a Python function `decode_all_1()` to reverse the operation of `encode_all_1()`.\n",
    "\n",
    "You may assume that the final text contains only uppercase Latin letters, lowercase Latin letters, and spaces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def decode_all_1(text):\n",
    "    \"\"\"\n",
    "    Decode all leet speak to Latin letters\n",
    "    IN: text, str, leet speak text\n",
    "    OUT: str, Latin letters text\n",
    "    \"\"\"\n",
    "    text = re.sub('4', 'A', text)\n",
    "    text = re.sub('8', 'B', text)\n",
    "    text = re.sub('\\(', 'C', text)\n",
    "    text = re.sub('\\)', 'D', text)\n",
    "    text = re.sub('3', 'E', text)\n",
    "    text = re.sub('f', 'F', text)\n",
    "    text = re.sub('6', 'G', text)\n",
    "    text = re.sub('#', 'H', text)\n",
    "    text = re.sub('!', 'I', text)\n",
    "    text = re.sub('j', 'J', text)\n",
    "    text = re.sub('\\|', 'K', text)\n",
    "    text = re.sub('1', 'L', text)\n",
    "    text = re.sub('M', 'M', text)\n",
    "    text = re.sub('n', 'N', text)\n",
    "    text = re.sub('0', 'O', text)\n",
    "    text = re.sub('9', 'P', text)\n",
    "    text = re.sub('2', 'Q', text)\n",
    "    text = re.sub('R', 'R', text)\n",
    "    text = re.sub('5', 'S', text)\n",
    "    text = re.sub('7', 'T', text)\n",
    "    text = re.sub('µ', 'U', text)\n",
    "    text = re.sub('√', 'V', text)\n",
    "    text = re.sub('ω', 'W', text)\n",
    "    text = re.sub('X', 'X', text)\n",
    "    text = re.sub('¥', 'Y', text)\n",
    "    text = re.sub('%', 'Z', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AABBCCDDEEFFGGHHIIJJKKLLMMNNOOPPQQRRSSTTUUVVWWXXYYZZ\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(decode_all_1(f\"4488(())33ff66##!!jj||11MMnn009922RR5577µµ√√ωωXX¥¥%%\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a Python function `encode_partially_1()` that takes a string and a number `p` between 0 and 1 as input, and encodes each Latin letter to leet speak with probability `p`.\n",
    "\n",
    "For example, if `p = 0.5`, then each Latin letter has a 50% chance of being encoded to leet speak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "def encode_partially_1(text, p):\n",
    "    \"\"\"\n",
    "    Encode each Latin letter to leet speak with probability p\n",
    "    IN: text, str, input text\n",
    "        p, float, probability of encoding\n",
    "    OUT: str, partially encoded text\n",
    "    \"\"\"\n",
    "    def replace_prob(match):\n",
    "        if random.random() < p:\n",
    "            char = match.group(0)\n",
    "            return {\n",
    "                'A': '4', 'a': '4', 'B': '8', 'b': '8',\n",
    "                'C': '(', 'c': '(', 'D': ')', 'd': ')',\n",
    "                'E': '3', 'e': '3', 'F': 'f', 'f': 'f',\n",
    "                'G': '6', 'g': '6', 'H': '#', 'h': '#',\n",
    "                'I': '!', 'i': '!', 'J': 'j', 'j': 'j',\n",
    "                'K': '|', 'k': '|', 'L': '1', 'l': '1',\n",
    "                'M': 'M', 'm': 'M', 'N': 'n', 'n': 'n',\n",
    "                'O': '0', 'o': '0', 'P': '9', 'p': '9',\n",
    "                'Q': '2', 'q': '2', 'R': 'R', 'r': 'R',\n",
    "                'S': '5', 's': '5', 'T': '7', 't': '7',\n",
    "                'U': 'µ', 'u': 'µ', 'V': '√', 'v': '√',\n",
    "                'W': 'ω', 'w': 'ω', 'X': 'X', 'x': 'X',\n",
    "                'Y': '¥', 'y': '¥', 'Z': '%', 'z': '%'\n",
    "            }[char]\n",
    "        return match.group(0)\n",
    "\n",
    "    return re.sub('[a-zA-Z]', replace_prob, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4A8BC())3EfF66##!Ijj||11MMnnO0PPQ2RR55TTµU√VWωXX¥¥Z%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(encode_partially_1(\"AABBCCDDEEFFGGHHIIJJKKLLMMNNOOPPQQRRSSTTUUVVWWXXYYZZ\", 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 1.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a Python function `decode_partially_1()` to reverse the operation of `encode_partially_1()`. \n",
    "\n",
    "Observation: Any Latin letter can be \"decoded\" as it is, since this version of leet speak does not map any character back to a Latin letter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def decode_partially_1(text):\n",
    "    \"\"\"\n",
    "    Decode each Latin letter from leet speak\n",
    "    IN: text, str, partially encoded text\n",
    "    OUT: str, partially decoded text\n",
    "    \"\"\"\n",
    "    text = re.sub('4', 'A', text)\n",
    "    text = re.sub('8', 'B', text)\n",
    "    text = re.sub('\\(', 'C', text)\n",
    "    text = re.sub('\\)', 'D', text)\n",
    "    text = re.sub('3', 'E', text)\n",
    "    text = re.sub('f', 'F', text)\n",
    "    text = re.sub('6', 'G', text)\n",
    "    text = re.sub('#', 'H', text)\n",
    "    text = re.sub('!', 'I', text)\n",
    "    text = re.sub('j', 'J', text)\n",
    "    text = re.sub('\\|', 'K', text)\n",
    "    text = re.sub('1', 'L', text)\n",
    "    text = re.sub('n', 'N', text)\n",
    "    text = re.sub('0', 'O', text)\n",
    "    text = re.sub('9', 'P', text)\n",
    "    text = re.sub('2', 'Q', text)\n",
    "    text = re.sub('5', 'S', text)\n",
    "    text = re.sub('7', 'T', text)\n",
    "    text = re.sub('µ', 'U', text)\n",
    "    text = re.sub('√', 'V', text)\n",
    "    text = re.sub('ω', 'W', text)\n",
    "    text = re.sub('¥', 'Y', text)\n",
    "    text = re.sub('%', 'Z', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AABBCCDDEEFFGGHHIIJJKKLLMMNNOOPPQQRRSSTTUUVVWWXXYYZZ\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(decode_partially_1(f\"448BCC)DE3fFG6##!!jJKKLLMMnn00PPQQRR55TTUU√√WWXX¥Y%%\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Level 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this level, users can define their own mapping of characters to leet speak as a JSON dictionary, ensuring no ambiguity (using a prefix-free code).\n",
    "\n",
    "A prefix-free code is a type of coding system in which **no code is the prefix of another code**. For example, if `C` is encoded as `(`, then no other character can be encoded as `(` or as a sequence of characters starting with `(`.\n",
    "\n",
    "There is a mathematical proof that **if a code is prefix-free, there is a unique way to decode the encoded text**. In other words, there is no ambiguity when decoding the encoded text.\n",
    "\n",
    "For example, the JSON dictionary for the basic mapping in Level 1 is:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"A\": [\"4\"],\n",
    "    \"B\": [\"8\"],\n",
    "    \"C\": [\"(\"],\n",
    "    \"D\": [\")\"],\n",
    "    \"E\": [\"3\"],\n",
    "    \"F\": [\"ƒ\"],\n",
    "    \"G\": [\"6\"],\n",
    "    \"H\": [\"#\"],\n",
    "    \"I\": [\"!\"],\n",
    "    \"J\": [\"]\"],\n",
    "    \"K\": [\"|\"],\n",
    "    \"L\": [\"1\"],\n",
    "    \"M\": [\"м\"],\n",
    "    \"N\": [\"и\"],\n",
    "    \"O\": [\"Ø\"],\n",
    "    \"P\": [\"9\"],\n",
    "    \"Q\": [\"2\"],\n",
    "    \"R\": [\"Я\"],\n",
    "    \"S\": [\"5\"],\n",
    "    \"T\": [\"7\"],\n",
    "    \"U\": [\"µ\"],\n",
    "    \"V\": [\"√\"],\n",
    "    \"W\": [\"ω\"],\n",
    "    \"X\": [\"Ж\"],\n",
    "    \"Y\": [\"¥\"],\n",
    "    \"Z\": [\"%\"]\n",
    "}\n",
    "```\n",
    "\n",
    "A more complex version that allows one Latin letter mapping to multiple leet speak characters or sequences of characters is:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"A\": [\"4\", \"@\", \"Д\"],\n",
    "    \"B\": [\"8\", \"ß\"],\n",
    "    \"C\": [\"(\", \"<\", \"©\", \"¢\"],\n",
    "    \"D\": [\")\", \">\"],\n",
    "    \"E\": [\"3\", \"£\"],\n",
    "    \"F\": [\"ƒ\"],\n",
    "    \"G\": [\"6\", \"&\"],\n",
    "    \"H\": [\"#\", \"|-|\"],\n",
    "    \"I\": [\"!\"],\n",
    "    \"J\": [\"]\", \"_|\"],\n",
    "    \"K\": [\"|<\"],\n",
    "    \"L\": [\"1\", \"|_\"],\n",
    "    \"M\": [\"м\", \"|\\/|\"],\n",
    "    \"N\": [\"и\", \"|\\\\|\"],\n",
    "    \"O\": [\"Ø\"],\n",
    "    \"P\": [\"9\", \"|°\"],\n",
    "    \"Q\": [\"2\"],\n",
    "    \"R\": [\"Я\", \"|~\"],\n",
    "    \"S\": [\"5\", \"$\", \"§\"],\n",
    "    \"T\": [\"7\", \"-|-\"],\n",
    "    \"U\": [\"µ\"],\n",
    "    \"V\": [\"√\"],\n",
    "    \"W\": [\"ω\", \"\\^/\"],\n",
    "    \"X\": [\"Ж\", \"×\"],\n",
    "    \"Y\": [\"¥\", \"γ\"],\n",
    "    \"Z\": [\"%\"]\n",
    "}\n",
    "```\n",
    "Notice The character `K` has been changed to `|<` instead of `|` to allow other characters to be mapped to a sequence starting with `|`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a Python function `check_prefix_free_2()` that takes a JSON file name as input and checks if the JSON file specifies a prefix-free code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def check_prefix_free_2(json_file):\n",
    "    \"\"\"\n",
    "    Check if the JSON file specifies a prefix-free code\n",
    "    IN: json_file, str, JSON file name\n",
    "    OUT: dict or None, dictionary of characters mapping to leet speak or None if not prefix-free\n",
    "    \"\"\"\n",
    "    with open(json_file, 'r') as f:\n",
    "        mapping = json.load(f)\n",
    "    \n",
    "    # Get all possible leet codes\n",
    "    all_codes = []\n",
    "    for codes in mapping.values():\n",
    "        all_codes.extend(codes)\n",
    "    \n",
    "    # Check if any code is a prefix of another\n",
    "    for code1 in all_codes:\n",
    "        for code2 in all_codes:\n",
    "            if code1 != code2 and (code2.startswith(code1) or code1.startswith(code2)):\n",
    "                return None\n",
    "    \n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': ['4'], 'B': ['8'], 'C': ['('], 'D': [')'], 'E': ['3'], 'F': ['f'], 'G': ['6'], 'H': ['#'], 'I': ['!'], 'J': ['j'], 'K': ['|'], 'L': ['1'], 'M': ['M'], 'N': ['n'], 'O': ['0'], 'P': ['9'], 'Q': ['2'], 'R': ['R'], 'S': ['5'], 'T': ['7'], 'U': ['u'], 'V': ['v'], 'W': ['w'], 'X': ['x'], 'Y': ['y'], 'Z': ['%']}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #check json file 1\n",
    "    json_file = 'examples.json'\n",
    "    result = check_prefix_free_2(json_file)\n",
    "    if result is not None:\n",
    "        print(check_prefix_free_2(json_file))\n",
    "    else:\n",
    "        print('This Code is NOT prefix free')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Code is NOT prefix free\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #check json file 2\n",
    "    json_file = 'examples2.json'\n",
    "    result = check_prefix_free_2(json_file)\n",
    "    if result is not None:\n",
    "        print(check_prefix_free_2(json_file))\n",
    "    else:\n",
    "        print('This Code is NOT prefix free')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a Python function `encode_partially_2()` that takes a string and a number `p` between `0` and `1` as input and encodes each Latin letter to leet speak with probability `p` using the user-defined mapping. When a multiple mapping is possible, choose one randomly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def encode_partially_2(text, p, mapping):\n",
    "    \"\"\"\n",
    "    Encode each Latin letter to leet speak with probability p using the user-defined mapping\n",
    "    IN: text, str, input text\n",
    "        p, float, probability of encoding\n",
    "        mapping, dict, user-defined mapping\n",
    "    OUT: str, partially encoded text\n",
    "    \"\"\"\n",
    "    def replace_prob(match):\n",
    "        if random.random() < p:\n",
    "            char = match.group(0).upper()\n",
    "            if char in mapping:\n",
    "                # Randomly choose one of the possible encodings\n",
    "                return random.choice(mapping[char])\n",
    "        return match.group(0)\n",
    "    \n",
    "    # Create pattern to match any mappable character\n",
    "    pattern = f\"[{''.join(mapping.keys())}]\"\n",
    "    # Apply substitution with probability\n",
    "    return re.sub(pattern, replace_prob, text, flags=re.IGNORECASE)\n",
    "```\n",
    "\n",
    "Or, you can create a constructor for `encode_partially_2()` that takes the mapping as an argument:\n",
    "\n",
    "```python\n",
    "def encode_partially_2(mapping):\n",
    "    \"\"\"\n",
    "    Constructor for encoding each Latin letter to leet speak with probability p using the user-defined mapping\n",
    "    IN: mapping, dict, user-defined mapping\n",
    "    OUT: function, (text: str, p: float) -> str, encode latin letters to leet speak with probability p\n",
    "    \"\"\"\n",
    "    # define the encoding function using the mapping\n",
    "    def encode_partially_2(text, p):\n",
    "        \"\"\"\n",
    "        Encode each Latin letter to leet speak with probability p using the user-defined mapping\n",
    "        IN: text, str, input text\n",
    "            p, float, probability of encoding\n",
    "        OUT: str, partially encoded text\n",
    "        \"\"\"\n",
    "        # specify the encoding logic using the mapping\n",
    "        pass\n",
    "\n",
    "    # return the encoding function\n",
    "    return encode_partially_2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "def encode_partially_2(text, p, mapping):\n",
    "    \"\"\"\n",
    "    Encode each Latin letter to leet speak with probability p using the user-defined mapping\n",
    "    IN: text, str, input text\n",
    "        p, float, probability of encoding\n",
    "        mapping, dict, user-defined mapping\n",
    "    OUT: str, partially encoded text\n",
    "    \"\"\"\n",
    "    def replace_prob(match):\n",
    "        if random.random() < p:\n",
    "            char = match.group(0).upper()\n",
    "            if char in mapping:\n",
    "                # Randomly choose one of the possible encodings\n",
    "                return random.choice(mapping[char])\n",
    "        return match.group(0)\n",
    "    \n",
    "    # Create pattern to match any mappable character\n",
    "    pattern = f\"[{''.join(mapping.keys())}]\"\n",
    "    # Apply substitution with probability\n",
    "    return re.sub(pattern, replace_prob, text, flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WAXInG\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    json_file = 'examples.json'\n",
    "    result = check_prefix_free_2(json_file)\n",
    "    print(encode_partially_2(\"WAXING\", 0.5, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m json_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexamples2.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m result \u001b[38;5;241m=\u001b[39m check_prefix_free_2(json_file)\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mencode_partially_2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWAXING\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[65], line 20\u001b[0m, in \u001b[0;36mencode_partially_2\u001b[1;34m(text, p, mapping)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Create pattern to match any mappable character\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[43mmapping\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Apply substitution with probability\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m re\u001b[38;5;241m.\u001b[39msub(pattern, replace_prob, text, flags\u001b[38;5;241m=\u001b[39mre\u001b[38;5;241m.\u001b[39mIGNORECASE)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    json_file = 'examples2.json'\n",
    "    result = check_prefix_free_2(json_file)\n",
    "    print(encode_partially_2(\"WAXING\", 0.5, result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a Python function `decode_partially_2()` to reverse the operation of `encode_partially_2()` using the user-defined mapping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def decode_partially_2(text, mapping):\n",
    "    \"\"\"\n",
    "    Decode each Latin letter from leet speak using the user-defined mapping\n",
    "    IN: text, str, partially encoded text\n",
    "        mapping, dict, user-defined mapping\n",
    "    OUT: str, partially decoded text\n",
    "    \"\"\"\n",
    "    # Create reverse mapping\n",
    "    reverse_mapping = {}\n",
    "    for letter, codes in mapping.items():\n",
    "        for code in codes:\n",
    "            reverse_mapping[re.escape(code)] = letter\n",
    "    \n",
    "    # Sort codes by length (longest first) to handle multi-character codes correctly\n",
    "    sorted_codes = sorted(reverse_mapping.keys(), key=len, reverse=True)\n",
    "    \n",
    "    # Create pattern for all possible codes\n",
    "    pattern = '|'.join(sorted_codes)\n",
    "    \n",
    "    def replace_with_letter(match):\n",
    "        return reverse_mapping[re.escape(match.group(0))]\n",
    "    \n",
    "    # Apply substitution\n",
    "    return re.sub(pattern, replace_with_letter, text)\n",
    "```\n",
    "\n",
    "Or, you can create a constructor for `decode_partially_2()` that takes the mapping as an argument:\n",
    "\n",
    "```python\n",
    "def decode_partially_2(mapping):\n",
    "    \"\"\"\n",
    "    Constructor for decoding each Latin letter from leet speak using the user-defined mapping\n",
    "    IN: mapping, dict, user-defined mapping\n",
    "    OUT: function, (text: str) -> str, decode latin letters from leet speak\n",
    "    \"\"\"\n",
    "    # define the decoding function using the mapping\n",
    "    def decode_partially_2(text):\n",
    "        \"\"\"\n",
    "        Decode each Latin letter from leet speak using the user-defined mapping\n",
    "        IN: text, str, partially encoded text\n",
    "        OUT: str, partially decoded text\n",
    "        \"\"\"\n",
    "        # specify the decoding logic using the mapping\n",
    "        pass\n",
    "\n",
    "    # return the decoding function\n",
    "    return decode_partially_2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "def decode_partially_2(text, mapping):\n",
    "    \"\"\"\n",
    "    Decode each Latin letter from leet speak using the user-defined mapping\n",
    "    IN: text, str, partially encoded text\n",
    "        mapping, dict, user-defined mapping\n",
    "    OUT: str, partially decoded text\n",
    "    \"\"\"\n",
    "    # Create reverse mapping\n",
    "    reverse_mapping = {}\n",
    "    for letter, codes in mapping.items():\n",
    "        for code in codes:\n",
    "            reverse_mapping[re.escape(code)] = letter\n",
    "    \n",
    "    # Sort codes by length (longest first) to handle multi-character codes correctly\n",
    "    sorted_codes = sorted(reverse_mapping.keys(), key=len, reverse=True)\n",
    "    \n",
    "    # Create pattern for all possible codes\n",
    "    pattern = '|'.join(sorted_codes)\n",
    "    \n",
    "    def replace_with_letter(match):\n",
    "        return reverse_mapping[re.escape(match.group(0))]\n",
    "    \n",
    "    # Apply substitution\n",
    "    return re.sub(pattern, replace_with_letter, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WAXING\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    json_file = 'examples.json'\n",
    "    result = check_prefix_free_2(json_file)\n",
    "    print(decode_partially_2(encode_partially_2(\"WAXING\", 0.5, result), result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m json_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexamples2.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m result \u001b[38;5;241m=\u001b[39m check_prefix_free_2(json_file)\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mencode_partially_2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWAXING\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(decode_partially_2(encode_partially_2(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWAXING\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, result), result))\n",
      "Cell \u001b[1;32mIn[65], line 20\u001b[0m, in \u001b[0;36mencode_partially_2\u001b[1;34m(text, p, mapping)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Create pattern to match any mappable character\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[43mmapping\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Apply substitution with probability\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m re\u001b[38;5;241m.\u001b[39msub(pattern, replace_prob, text, flags\u001b[38;5;241m=\u001b[39mre\u001b[38;5;241m.\u001b[39mIGNORECASE)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    json_file = 'examples2.json'\n",
    "    result = check_prefix_free_2(json_file)\n",
    "    print(encode_partially_2(\"WAXING\", 0.5, result))\n",
    "    print(decode_partially_2(encode_partially_2(\"WAXING\", 0.5, result), result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Level 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this level:\n",
    "- Words can be emphasized by adding the suffix \"-zorz\". For example, \"leet\" can be emphasized as \"leetzorz\" and further encoded to \"1337%or|~z\".\n",
    "- Users can define their own mapping, not only for single Latin letters but also for words, to leet speak without ambiguity (using a prefix-free code).\n",
    "\n",
    "For example: \n",
    "\n",
    "```json\n",
    "{\n",
    "    \"words\": {\n",
    "        \"real\": [\"٢٤٨١\"],\n",
    "        \"eye\": [\"٤٢٤\"],\n",
    "        \"age\": [\"٨٩٤\"],\n",
    "        \"euro\": [\"٤٧٢٥\"],\n",
    "        \"total\": [\"٢٥٢٨١\"]\n",
    "    },\n",
    "    \"letters\": {\n",
    "        \"A\": [\"4\", \"@\", \"Д\"],\n",
    "        \"B\": [\"8\", \"ß\"],\n",
    "        \"C\": [\"(\", \"<\", \"©\", \"¢\"],\n",
    "        \"D\": [\")\", \">\"],\n",
    "        \"E\": [\"3\", \"£\"],\n",
    "        \"F\": [\"ƒ\"],\n",
    "        \"G\": [\"6\", \"&\"],\n",
    "        \"H\": [\"#\", \"|-|\"],\n",
    "        \"I\": [\"!\"],\n",
    "        \"J\": [\"]\", \"_|\"],\n",
    "        \"K\": [\"|<\"],\n",
    "        \"L\": [\"1\", \"|_\"],\n",
    "        \"M\": [\"м\", \"|\\/|\"],\n",
    "        \"N\": [\"и\", \"|\\\\|\"],\n",
    "        \"O\": [\"Ø\"],\n",
    "        \"P\": [\"9\", \"|°\"],\n",
    "        \"Q\": [\"2\"],\n",
    "        \"R\": [\"Я\", \"|~\"],\n",
    "        \"S\": [\"5\", \"$\", \"§\"],\n",
    "        \"T\": [\"7\", \"-|-\"],\n",
    "        \"U\": [\"µ\"],\n",
    "        \"V\": [\"√\"],\n",
    "        \"W\": [\"ω\", \"\\^/\"],\n",
    "        \"X\": [\"Ж\", \"×\"],\n",
    "        \"Y\": [\"¥\", \"γ\"],\n",
    "        \"Z\": [\"%\"]\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encoding and decoding sequence is as follows:\n",
    "\n",
    "```mermaid\n",
    "graph TB\n",
    "    Original([\"Original text\"])\n",
    "    AddSuffix[\"Add suffix '-zorz' to emphasize\"]\n",
    "    EncodeWord[\"Encode words to leet speak\"]\n",
    "    EncodeLetter[\"Encode letters to leet speak\"]\n",
    "    LeetSpeak([\"Leet speak text\"])\n",
    "    DecodeLetter[\"Decode letters from leet speak\"]\n",
    "    DecodeWord[\"Decode words from leet speak\"]\n",
    "    RemoveSuffix[\"Remove suffix '-zorz'\"]\n",
    "    Original2([\"Original text\"])\n",
    "\n",
    "    Original --> AddSuffix\n",
    "    AddSuffix --> EncodeWord\n",
    "    EncodeWord --> EncodeLetter\n",
    "    EncodeLetter --> LeetSpeak\n",
    "    LeetSpeak --> DecodeLetter\n",
    "    DecodeLetter --> DecodeWord\n",
    "    DecodeWord --> RemoveSuffix\n",
    "    RemoveSuffix --> Original2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 3.1\n",
    "\n",
    "Write a Python function `check_prefix_free_3()` similar to Task 2.1 that checks if the JSON file specifies a prefix-free code for both words and letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_prefix_free_3(json_file):\n",
    "    \"\"\"\n",
    "    Check if the JSON file specifies a prefix-free code for both words and letters\n",
    "    IN: json_file, str, JSON file name\n",
    "    OUT: dict or None, dictionary of characters mapping to leet speak or None if not prefix-free\n",
    "    \"\"\"\n",
    "    with open(json_file, 'r') as f:\n",
    "        mapping = json.load(f)\n",
    "    \n",
    "    # Get all codes from both words and letters\n",
    "    all_codes = []\n",
    "    if 'words' in mapping:\n",
    "        for codes in mapping['words'].values():\n",
    "            all_codes.extend(codes)\n",
    "    if 'letters' in mapping:\n",
    "        for codes in mapping['letters'].values():\n",
    "            all_codes.extend(codes)\n",
    "    \n",
    "    # Check for prefix relationships\n",
    "    for code1 in all_codes:\n",
    "        for code2 in all_codes:\n",
    "            if code1 != code2 and (code2.startswith(code1) or code1.startswith(code2)):\n",
    "                return None\n",
    "    \n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'words': {'hello': ['h3ll0x'], 'world': ['w0rld1'], 'computer': ['c0mpu74r'], 'python': ['py7h0n2'], 'code': ['c0d3x'], 'programming': ['pr06x'], 'testing': ['73s7ing'], 'debug': ['d3bu6x'], 'syntax': ['syn7x1'], 'function': ['funk7x']}, 'letters': {'A': ['4x'], 'B': ['8x'], 'C': ['(x'], 'D': [')x'], 'E': ['3x'], 'F': ['fx'], 'G': ['6x'], 'H': ['#x'], 'I': ['!x'], 'J': ['jx'], 'K': ['kx'], 'L': ['1x'], 'M': ['mx'], 'N': ['nx'], 'O': ['0x'], 'P': ['9x'], 'Q': ['qx'], 'R': ['rx'], 'S': ['5x'], 'T': ['7x'], 'U': ['ux'], 'V': ['vx'], 'W': ['wx'], 'X': ['xx'], 'Y': ['yx'], 'Z': ['zx']}}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    json_file = 'examples3.json'\n",
    "    result = check_prefix_free_3(json_file)\n",
    "    if result is not None:\n",
    "        print(check_prefix_free_3(json_file))\n",
    "    else:\n",
    "        print(\"The Code is NOT Prefix Free\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a Python function `add_emphasis_3()` that takes a string and a list of important words as input and emphasizes the important words in the string by adding the suffix \"-zorz\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import re\n",
    "\n",
    "def add_emphasis_3(text, important_words):\n",
    "    \"\"\"\n",
    "    Add emphasis to important words by adding the suffix '-zorz'\n",
    "    IN: text, str, input text\n",
    "        important_words, list[str], list of important words\n",
    "    OUT: str, text with emphasized words\n",
    "    \"\"\"\n",
    "    def replace_word(match):\n",
    "        word = match.group(0)\n",
    "        if word.lower() in [w.lower() for w in important_words]:\n",
    "            return f\"{word}-zorz\"\n",
    "        return word\n",
    "    \n",
    "    # Create pattern to match whole words\n",
    "    pattern = r'\\b(' + '|'.join(map(re.escape, important_words)) + r')\\b'\n",
    "    return re.sub(pattern, replace_word, text, flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    important_words = ['pancakes', 'donuts']\n",
    "    test_text = \"hello there pancakes and donuts\"\n",
    "    result = add_emphasis_3(test_text, important_words)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 3.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a Python function `encode_partially_words_3()` that takes a string and a number `p` between `0` and `1` as input and encodes words to leet speak with probability `p` using the user-defined mapping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import random\n",
    "import json\n",
    "import re\n",
    "def encode_partially_words_3(text, p, mapping):\n",
    "    \"\"\"\n",
    "    Encode words to leet speak with probability p using the user-defined mapping\n",
    "    IN: text, str, input text\n",
    "        p, float, probability of encoding\n",
    "        mapping, dict, user-defined mapping\n",
    "    OUT: str, partially encoded text\n",
    "    \"\"\"\n",
    "    def encoder(text, p):\n",
    "        def replace_word(match):\n",
    "            word = match.group(0)\n",
    "            if random.random() < p and word.lower() in mapping['words']:\n",
    "                return random.choice(mapping['words'][word.lower()])\n",
    "            return word\n",
    "        \n",
    "        # Create pattern to match whole words from mapping\n",
    "        pattern = r'\\b(' + '|'.join(map(re.escape, mapping['words'].keys())) + r')\\b'\n",
    "        return re.sub(pattern, replace_word, text, flags=re.IGNORECASE)\n",
    "    \n",
    "    return encoder\n",
    "```\n",
    "\n",
    "Or, you can create a constructor for `encode_partially_words_3()` that takes the mapping as an argument:\n",
    "\n",
    "```python\n",
    "def encode_partially_words_3(mapping):\n",
    "    \"\"\"\n",
    "    Constructor for encoding words to leet speak with probability p using the user-defined mapping\n",
    "    IN: mapping, dict, user-defined mapping\n",
    "    OUT: function, (text: str, p: float) -> str, encode words to leet speak with probability p\n",
    "    \"\"\"\n",
    "    # define the encoding function using the mapping\n",
    "    def encode_partially_words_3(text, p):\n",
    "        \"\"\"\n",
    "        Encode words to leet speak with probability p using the user-defined mapping\n",
    "        IN: text, str, input text\n",
    "            p, float, probability of encoding\n",
    "        OUT: str, partially encoded text\n",
    "        \"\"\"\n",
    "        # specify the encoding logic using the mapping\n",
    "        pass\n",
    "\n",
    "    # return the encoding function\n",
    "    return encode_partially_words_3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import re\n",
    "def encode_partially_words_3(text, p, mapping):\n",
    "    \"\"\"\n",
    "    Encode words to leet speak with probability p using the user-defined mapping\n",
    "    IN: text, str, input text\n",
    "        p, float, probability of encoding\n",
    "        mapping, dict, user-defined mapping\n",
    "    OUT: str, partially encoded text\n",
    "    \"\"\"\n",
    "    def replace_word(match):\n",
    "        word = match.group(0)\n",
    "        if random.random() < p and word.lower() in mapping['words']:\n",
    "            return random.choice(mapping['words'][word.lower()])\n",
    "        return word\n",
    "    \n",
    "    # Create pattern to match whole words from mapping\n",
    "    pattern = r'\\b(' + '|'.join(map(re.escape, mapping['words'].keys())) + r')\\b'\n",
    "    return re.sub(pattern, replace_word, text, flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    json_file = 'examples3.json'\n",
    "    result = check_prefix_free_3(json_file)\n",
    "    print(encode_partially_words_3('code code code just stick to the code', 0.5, result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 3.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write Python function `encode_partially_letters_3()` similar to Task 2.2 that encodes each Latin letter to leet speak with probability `p` using the user-defined mapping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "def encode_partially_letters_3(text, p, mapping):\n",
    "    \"\"\"\n",
    "    Encode each Latin letter to leet speak with probability p using the user-defined mapping\n",
    "    IN: text, str, input text\n",
    "        p, float, probability of encoding\n",
    "        mapping, dict, user-defined mapping\n",
    "    OUT: str, partially encoded text\n",
    "    \"\"\"\n",
    "    def encoder(text, p):\n",
    "        def replace_letter(match):\n",
    "            letter = match.group(0)\n",
    "            if random.random() < p:\n",
    "                upper_letter = letter.upper()\n",
    "                if upper_letter in mapping['letters']:\n",
    "                    return random.choice(mapping['letters'][upper_letter])\n",
    "            return letter\n",
    "        \n",
    "        # Create pattern to match any letter from mapping\n",
    "        pattern = f\"[{''.join(mapping['letters'].keys())}]\"\n",
    "        return re.sub(pattern, replace_letter, text, flags=re.IGNORECASE)\n",
    "    \n",
    "    return encoder\n",
    "```\n",
    "\n",
    "Or, you can create a constructor for `encode_partially_letters_3()` that takes the mapping as an argument:\n",
    "\n",
    "```python\n",
    "def encode_partially_letters_3(mapping):\n",
    "    \"\"\"\n",
    "    Constructor for encoding each Latin letter to leet speak with probability p using the user-defined mapping\n",
    "    IN: mapping, dict, user-defined mapping\n",
    "    OUT: function, (text: str, p: float) -> str, encode latin letters to leet speak with probability p\n",
    "    \"\"\"\n",
    "    # define the encoding function using the mapping\n",
    "    def encode_partially_letters_3(text, p):\n",
    "        \"\"\"\n",
    "        Encode each Latin letter to leet speak with probability p using the user-defined mapping\n",
    "        IN: text, str, input text\n",
    "            p, float, probability of encoding\n",
    "        OUT: str, partially encoded text\n",
    "        \"\"\"\n",
    "        # specify the encoding logic using the mapping\n",
    "        pass\n",
    "\n",
    "    # return the encoding function\n",
    "    return encode_partially_letters_3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "def encode_partially_letters_3(text, p, mapping):\n",
    "    \"\"\"\n",
    "    Encode each Latin letter to leet speak with probability p using the user-defined mapping\n",
    "    IN: text, str, input text\n",
    "        p, float, probability of encoding\n",
    "        mapping, dict, user-defined mapping\n",
    "    OUT: str, partially encoded text\n",
    "    \"\"\"\n",
    "    def replace_letter(match):\n",
    "        letter = match.group(0)\n",
    "        if random.random() < p:\n",
    "            upper_letter = letter.upper()\n",
    "            if upper_letter in mapping['letters']:\n",
    "                return random.choice(mapping['letters'][upper_letter])\n",
    "        return letter\n",
    "    \n",
    "    # Create pattern to match any letter from mapping\n",
    "    pattern = f\"[{''.join(mapping['letters'].keys())}]\"\n",
    "    return re.sub(pattern, replace_letter, text, flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    json_file = 'examples3.json'\n",
    "    result = check_prefix_free_3(json_file)\n",
    "    print(encode_partially_letters_3(\"Hello World\", 0.5, result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 3.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a Python function `decode_partially_words_3()` to reverse the operation of `encode_partially_words_3()` using the user-defined mapping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import random\n",
    "import json\n",
    "import re\n",
    "def decode_partially_words_3(text, mapping):\n",
    "    \"\"\"\n",
    "    Decode words from leet speak using the user-defined mapping\n",
    "    IN: text, str, partially encoded text\n",
    "        mapping, dict, user-defined mapping\n",
    "    OUT: str, partially decoded text\n",
    "    \"\"\"\n",
    "    reverse_mapping = {}\n",
    "    for word, codes in mapping['words'].items():\n",
    "        for code in codes:\n",
    "            reverse_mapping[re.escape(code)] = word\n",
    "    \n",
    "    # Sort codes by length (longest first) to handle potential overlaps\n",
    "    sorted_codes = sorted(reverse_mapping.keys(), key=len, reverse=True)\n",
    "    \n",
    "    # Create pattern and replace all matching codes with their original words\n",
    "    pattern = '|'.join(sorted_codes)\n",
    "    return re.sub(pattern, lambda m: reverse_mapping[re.escape(m.group(0))], text)\n",
    "```\n",
    "\n",
    "Or, you can create a constructor for `decode_partially_words_3()` that takes the mapping as an argument:\n",
    "\n",
    "```python\n",
    "import random\n",
    "import json\n",
    "import re\n",
    "def decode_partially_words_3(mapping):\n",
    "    \"\"\"\n",
    "    Constructor for decoding words from leet speak using the user-defined mapping\n",
    "    IN: mapping, dict, user-defined mapping\n",
    "    OUT: function, (text: str) -> str, decode words from leet speak\n",
    "    \"\"\"\n",
    "    # define the decoding function using the mapping\n",
    "    # Create reverse mapping for words\n",
    "    reverse_mapping = {}\n",
    "    for word, codes in mapping['words'].items():\n",
    "        for code in codes:\n",
    "            reverse_mapping[re.escape(code)] = word\n",
    "    \n",
    "    # Sort codes by length (longest first) to handle potential overlaps\n",
    "    sorted_codes = sorted(reverse_mapping.keys(), key=len, reverse=True)\n",
    "    \n",
    "    def decoder(text):\n",
    "        \"\"\"\n",
    "        Decode words from leet speak using the user-defined mapping\n",
    "        IN: text, str, partially encoded text\n",
    "        OUT: str, partially decoded text\n",
    "        \"\"\"\n",
    "        pattern = '|'.join(sorted_codes)\n",
    "        return re.sub(pattern, lambda m: reverse_mapping[re.escape(m.group(0))], text)\n",
    "    \n",
    "    return decoder\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import re\n",
    "def decode_partially_words_3(text, mapping):\n",
    "    \"\"\"\n",
    "    Decode words from leet speak using the user-defined mapping\n",
    "    IN: text, str, partially encoded text\n",
    "        mapping, dict, user-defined mapping\n",
    "    OUT: str, partially decoded text\n",
    "    \"\"\"\n",
    "    reverse_mapping = {}\n",
    "    for word, codes in mapping['words'].items():\n",
    "        for code in codes:\n",
    "            reverse_mapping[re.escape(code)] = word\n",
    "    \n",
    "    # Sort codes by length (longest first) to handle potential overlaps\n",
    "    sorted_codes = sorted(reverse_mapping.keys(), key=len, reverse=True)\n",
    "    \n",
    "    # Create pattern and replace all matching codes with their original words\n",
    "    pattern = '|'.join(sorted_codes)\n",
    "    return re.sub(pattern, lambda m: reverse_mapping[re.escape(m.group(0))], text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    json_file = 'examples3.json'\n",
    "    result = check_prefix_free_3(json_file)\n",
    "    print(decode_partially_words_3('5yn7x', result))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 3.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a Python function `decode_partially_letters_3()` to reverse the operation of `encode_partially_letters_3()` using the user-defined mapping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import re\n",
    "import json\n",
    "import random\n",
    "def decode_partially_letters_3(text, mapping):\n",
    "    \"\"\"\n",
    "    Decode each Latin letter from leet speak using the user-defined mapping\n",
    "    IN: text, str, partially encoded text\n",
    "        mapping, dict, user-defined mapping\n",
    "    OUT: str, partially decoded text\n",
    "    \"\"\"\n",
    "    reverse_mapping = {}\n",
    "    for letter, codes in mapping['letters'].items():\n",
    "        for code in codes:\n",
    "            reverse_mapping[re.escape(code)] = letter\n",
    "    \n",
    "    # Sort codes by length (longest first) to handle potential overlaps\n",
    "    sorted_codes = sorted(reverse_mapping.keys(), key=len, reverse=True)\n",
    "    \n",
    "    # Create pattern and replace all matching codes with their original letters\n",
    "    pattern = '|'.join(sorted_codes)\n",
    "    return re.sub(pattern, lambda m: reverse_mapping[re.escape(m.group(0))], text)\n",
    "```\n",
    "\n",
    "Or, you can create a constructor for `decode_partially_letters_3()` that takes the mapping as an argument:\n",
    "\n",
    "```python\n",
    "def decode_partially_letters_3(mapping):\n",
    "    \"\"\"\n",
    "    Constructor for decoding each Latin letter from leet speak using the user-defined mapping\n",
    "    IN: mapping, dict, user-defined mapping\n",
    "    OUT: function, (text: str) -> str, decode latin letters from leet speak\n",
    "    \"\"\"\n",
    "    # define the decoding function using the mapping\n",
    "    # Create reverse mapping for letters\n",
    "    reverse_mapping = {}\n",
    "    for letter, codes in mapping['letters'].items():\n",
    "        for code in codes:\n",
    "            reverse_mapping[re.escape(code)] = letter\n",
    "    \n",
    "    # Sort codes by length (longest first) to handle potential overlaps\n",
    "    sorted_codes = sorted(reverse_mapping.keys(), key=len, reverse=True)\n",
    "    \n",
    "    def decoder(text):\n",
    "        \"\"\"\n",
    "        Decode each Latin letter from leet speak using the user-defined mapping\n",
    "        IN: text, str, partially encoded text\n",
    "        OUT: str, partially decoded text\n",
    "        \"\"\"\n",
    "        pattern = '|'.join(sorted_codes)\n",
    "        return re.sub(pattern, lambda m: reverse_mapping[re.escape(m.group(0))], text)\n",
    "    \n",
    "    return decoder\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import random\n",
    "def decode_partially_letters_3(text, mapping):\n",
    "    \"\"\"\n",
    "    Decode each Latin letter from leet speak using the user-defined mapping\n",
    "    IN: text, str, partially encoded text\n",
    "        mapping, dict, user-defined mapping\n",
    "    OUT: str, partially decoded text\n",
    "    \"\"\"\n",
    "    reverse_mapping = {}\n",
    "    for letter, codes in mapping['letters'].items():\n",
    "        for code in codes:\n",
    "            reverse_mapping[re.escape(code)] = letter\n",
    "    \n",
    "    # Sort codes by length (longest first) to handle potential overlaps\n",
    "    sorted_codes = sorted(reverse_mapping.keys(), key=len, reverse=True)\n",
    "    \n",
    "    # Create pattern and replace all matching codes with their original letters\n",
    "    pattern = '|'.join(sorted_codes)\n",
    "    return re.sub(pattern, lambda m: reverse_mapping[re.escape(m.group(0))], text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    json_file = 'examples3.json'\n",
    "    result = check_prefix_free_3(json_file)\n",
    "    print(decode_partially_letters_3('70', result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 3.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a Python function `remove_emphasis_3()` that takes a string and removes the suffix \"-zorz\" from words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def remove_emphasis_3(text):\n",
    "    \"\"\"\n",
    "    Remove the suffix '-zorz' from words\n",
    "    IN: text, str, input text\n",
    "    OUT: str, text with emphasized suffix `-zorz` removed\n",
    "    \"\"\"\n",
    "    return re.sub(r'-zorz\\b', '', text)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_emphasis_3(text):\n",
    "    \"\"\"\n",
    "    Remove the suffix '-zorz' from words\n",
    "    IN: text, str, input text\n",
    "    OUT: str, text with emphasized suffix `-zorz` removed\n",
    "    \"\"\"\n",
    "    return re.sub(r'-zorz\\b', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(remove_emphasis_3('hello-zorz'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Blashki, Katherine; Nichol, Sophie (2005). \"Game Geek's Goss: Linguistic Creativity In Young Males Within An Online University Forum\" (PDF). Australian Journal of Emerging Technologies and Society. 3 (2): 77–86.\n",
    "> - LeBlanc, Tracy Rene (May 2005). \"Is There A Translator in Teh House?\": Cultural and Discourse Analysis of a Virtual Speech Community on an Internet Message Board (MA thesis). Louisiana State University. doi:10.31390/gradschool_theses.4112\n",
    "> - Perea, M.; Duñabeitia, J. A.; Carreiras, M. (2008). \"R34D1Ng W0Rd5 W1Th Numb3R5\" (PDF). Journal of Experimental Psychology: Human Perception and Performance. 34 (1): 237–241. doi:10.1037/0096-1523.34.1.237. ISSN 0096-1523. PMID 18248151. S2CID 6054151\n",
    "> - Raymond, Eric R.; Steele, Guy L. (1996). The New Hacker's Dictionary. MIT Press. ISBN 978-0-262-68092-9."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
